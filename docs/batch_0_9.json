[
  {
    "title": "A quantitative high-resolution computational mechanics cell model\nfor growing and regenerating tissues",
    "description": "This paper presents a 3D high-resolution cell-based model that integrates information from measurements to provide a refined and quantitative understanding of the impact of cell-biomechanical effects on the closure of drug-induced lesions in liver. The model represents each cell individually and is constructed by a discrete, physically scalable network of viscoelastic elements, capable of mimicking realistic cell deformation and supplying information at subcellular scales. The cells have the capability to migrate, grow, and divide, and the nature and parameters of their mechanical elements can be inferred from comparisons with optical stretcher experiments.",
    "tags": [
      "Cell-based model",
      "High resolution cell model",
      "Cell mechanics",
      "Liver regeneration",
      "Optical stretcher"
    ],
    "document": "documents/10237_2019_Article_1204.pdf"
  },
  {
    "title": "Dueling Network Architectures for Deep Reinforcement Learning",
    "description": "This paper presents a new neural network architecture for model-free reinforcement learning called the dueling network. The dueling network uses two separate estimators: one for the state value function and one for the state-dependent action advantage function. This architecture leads to better policy evaluation in the presence of many similar-valued actions and enables the RL agent to outperform the state-of-the-art on the Atari 2600 domain.",
    "tags": [
      "Deep Reinforcement Learning",
      "Dueling Network",
      "Policy Evaluation",
      "Atari 2600",
      "Advantage Function"
    ],
    "document": "documents/1511.06581v3.pdf"
  },
  {
    "title": "17 Best\nOpenAl Sora\nAl Video\nExamples\n(2025)",
    "description": "This article showcases the best examples of videos generated with OpenAI's Sora, a new AI model that generates realistic and imaginative video content from text instructions.  Sora can generate videos up to a minute long, maintaining high visual quality and closely adhering to the provided prompts.",
    "tags": [
      "OpenAI",
      "Sora",
      "AI Video Generation",
      "Text-to-Video",
      "AI Models"
    ],
    "document": "documents/17 Best OpenAI Sora AI Video Examples (2025).pdf"
  },
  {
    "title": "DeepFM: A Factorization-Machine based Neural Network for CTR Prediction",
    "description": "The paper introduces DeepFM, a novel neural network model for Click-Through Rate (CTR) prediction. DeepFM combines the power of Factorization Machines (FM) and deep learning, enabling it to effectively model both low-order and high-order feature interactions. This approach eliminates the need for feature engineering, unlike existing models like Wide & Deep. Experiments on benchmark and commercial datasets demonstrate DeepFM's superior performance in CTR prediction compared to other state-of-the-art models.",
    "tags": [
      "Click-Through Rate Prediction",
      "Factorization Machines",
      "Deep Learning",
      "Recommender Systems",
      "Feature Interactions"
    ],
    "document": "documents/1703.04247v1.pdf"
  },
  {
    "title": "NATURAL TTS SYNTHESIS BY CONDITIONING WAVENET ON MEL SPECTROGRAM PREDICTIONS",
    "description": "This paper introduces Tacotron 2, a neural network architecture for speech synthesis that directly generates speech from text. The system comprises two main components: a recurrent sequence-to-sequence feature prediction network that maps character embeddings to mel-scale spectrograms, and a modified WaveNet model that synthesizes time-domain waveforms from these spectrograms. Tacotron 2 achieves a mean opinion score (MOS) of 4.53, comparable to professionally recorded speech (MOS of 4.58), demonstrating its ability to generate natural-sounding speech.",
    "tags": [
      "Text-to-Speech Synthesis (TTS)",
      "WaveNet",
      "Tacotron 2",
      "Mel Spectrogram",
      "Neural Network Architecture"
    ],
    "document": "documents/1712.05884v2.pdf"
  },
  {
    "title": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric",
    "description": "This paper explores the effectiveness of deep features as a perceptual metric for image similarity. The authors introduce a new dataset of human perceptual similarity judgments and systematically evaluate deep features across different architectures and tasks, comparing them with classic metrics. They find that deep features, even those from networks trained on different tasks like image classification, outperform previous metrics by large margins. This suggests that perceptual similarity is an emergent property shared across deep visual representations.",
    "tags": [
      "Perceptual Similarity",
      "Deep Features",
      "Image Quality Assessment",
      "Computer Vision",
      "Deep Learning"
    ],
    "document": "documents/1801.03924v2.pdf"
  },
  {
    "document": "documents/1803.08494v3.pdf",
    "error": "Exceeded retry limit",
    "title": "",
    "description": "",
    "tags": []
  },
  {
    "title": "Who Let The Dogs Out?\nModeling Dog Behavior From Visual Data",
    "description": "This research paper focuses on directly modeling a visually intelligent agent, specifically a dog, using visual data to predict its actions and plan movements. The authors introduce DECADE, a dataset of ego-centric videos from a dog's perspective, along with corresponding movement data captured using IMUs. They develop models that can predict the dog's future movements (acting like a dog) and plan sequences of actions to reach a desired state (planning like a dog). The paper also explores using the learned representations for other tasks like walkable surface estimation and scene classification, showing promising results and generalization capabilities.",
    "tags": [
      "Computer Vision",
      "Visually Intelligent Agents",
      "Dog Behavior Modeling",
      "Action Prediction",
      "Movement Planning"
    ],
    "document": "documents/1803.10827.pdf"
  },
  {
    "title": "Neural Design Network: Graphic Layout Generation with Constraints",
    "description": "The document presents a novel method for generating graphic design layouts that adhere to user-specified constraints. This method, called Neural Design Network (NDN), leverages graph neural networks to model relationships between design components and utilizes a three-module framework: relation prediction, layout generation, and refinement. The authors demonstrate the effectiveness of NDN through quantitative and qualitative experiments on three datasets, showing superior performance compared to existing methods in terms of realism, alignment, and visual quality. Additionally, they showcase real-world applications like constructing designs from generated layouts and a layout recommendation system.",
    "tags": [
      "Graphic Design",
      "Layout Generation",
      "Neural Networks",
      "Graph Neural Networks",
      "User Constraints"
    ],
    "document": "documents/1912.09421v2.pdf"
  },
  {
    "document": "documents/2001.05308v1.pdf",
    "error": "Exceeded retry limit",
    "title": "",
    "description": "",
    "tags": []
  }
]